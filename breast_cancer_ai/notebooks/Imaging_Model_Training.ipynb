{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "996669a3",
   "metadata": {},
   "source": [
    "# üî¨ Breast Cancer Histopathology Classification\n",
    "## Complete Training Pipeline with ResNet50 + GradCAM\n",
    "\n",
    "This notebook provides:\n",
    "1. **Data Loading** - BreakHis dataset (benign vs malignant)\n",
    "2. **Proper Data Split** - Train/Val/Test with stratification\n",
    "3. **Data Augmentation** - Prevent overfitting\n",
    "4. **Transfer Learning** - Fine-tune ResNet50\n",
    "5. **Training Loop** - With early stopping\n",
    "6. **Evaluation** - Accuracy, AUC, Confusion Matrix, Classification Report\n",
    "7. **GradCAM Visualization** - Explainability\n",
    "8. **Model Export** - Save for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb15efd",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b13a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements (run once)\n",
    "!pip install torch torchvision scikit-learn matplotlib seaborn pillow tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, confusion_matrix, \n",
    "    classification_report, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a2169",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Modify these paths for your setup\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Data paths - UPDATE THESE!\n",
    "    'data_dir': './data/Breakhis-400x',  # Contains 'benign' and 'malignant' folders\n",
    "    'model_save_path': './models/imaging_model_trained.pth',\n",
    "    \n",
    "    # Training parameters\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 25,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    \n",
    "    # Data split\n",
    "    'val_split': 0.15,\n",
    "    'test_split': 0.15,\n",
    "    \n",
    "    # Image settings\n",
    "    'image_size': 224,\n",
    "    \n",
    "    # Early stopping\n",
    "    'patience': 5,\n",
    "    \n",
    "    # Random seed\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "\n",
    "print(\"üìã Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960a2ec",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ffed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# OPTION A: Load from local BreakHis folder\n",
    "# ============================================================\n",
    "\n",
    "def load_breakhis_data(data_dir):\n",
    "    \"\"\"Load image paths and labels from BreakHis directory structure.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Load benign images\n",
    "    benign_dir = data_dir / 'benign'\n",
    "    if benign_dir.exists():\n",
    "        for img_path in benign_dir.glob('*.png'):\n",
    "            image_paths.append(str(img_path))\n",
    "            labels.append(0)  # 0 = Benign\n",
    "        for img_path in benign_dir.glob('*.jpg'):\n",
    "            image_paths.append(str(img_path))\n",
    "            labels.append(0)\n",
    "    \n",
    "    # Load malignant images\n",
    "    malignant_dir = data_dir / 'malignant'\n",
    "    if malignant_dir.exists():\n",
    "        for img_path in malignant_dir.glob('*.png'):\n",
    "            image_paths.append(str(img_path))\n",
    "            labels.append(1)  # 1 = Malignant\n",
    "        for img_path in malignant_dir.glob('*.jpg'):\n",
    "            image_paths.append(str(img_path))\n",
    "            labels.append(1)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "# Try to load data\n",
    "try:\n",
    "    image_paths, labels = load_breakhis_data(CONFIG['data_dir'])\n",
    "    print(f\"‚úÖ Loaded {len(image_paths)} images from {CONFIG['data_dir']}\")\n",
    "    print(f\"   Benign: {labels.count(0)}\")\n",
    "    print(f\"   Malignant: {labels.count(1)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    print(\"\\nüìå Please ensure your data directory has this structure:\")\n",
    "    print(\"   data_dir/\")\n",
    "    print(\"   ‚îú‚îÄ‚îÄ benign/\")\n",
    "    print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ image1.png\")\n",
    "    print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ ...\")\n",
    "    print(\"   ‚îî‚îÄ‚îÄ malignant/\")\n",
    "    print(\"       ‚îú‚îÄ‚îÄ image1.png\")\n",
    "    print(\"       ‚îî‚îÄ‚îÄ ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f568055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# OPTION B: Download BreakHis from Kaggle (if not available locally)\n",
    "# ============================================================\n",
    "\n",
    "# Uncomment and run if you need to download the dataset\n",
    "'''\n",
    "# Install kaggle API\n",
    "!pip install kaggle --quiet\n",
    "\n",
    "# Upload your kaggle.json API key first, then:\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download BreakHis dataset\n",
    "!kaggle datasets download -d ambarish/breakhis\n",
    "!unzip -q breakhis.zip -d ./data/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def show_sample_images(image_paths, labels, n_samples=8):\n",
    "    \"\"\"Display sample images from each class.\"\"\"\n",
    "    fig, axes = plt.subplots(2, n_samples//2, figsize=(16, 8))\n",
    "    \n",
    "    # Get indices for each class\n",
    "    benign_idx = [i for i, l in enumerate(labels) if l == 0][:n_samples//2]\n",
    "    malignant_idx = [i for i, l in enumerate(labels) if l == 1][:n_samples//2]\n",
    "    \n",
    "    # Plot benign\n",
    "    for i, idx in enumerate(benign_idx):\n",
    "        img = Image.open(image_paths[idx])\n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].set_title('Benign', color='green', fontsize=12)\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot malignant\n",
    "    for i, idx in enumerate(malignant_idx):\n",
    "        img = Image.open(image_paths[idx])\n",
    "        axes[1, i].imshow(img)\n",
    "        axes[1, i].set_title('Malignant', color='red', fontsize=12)\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Histopathology Images', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if len(image_paths) > 0:\n",
    "    show_sample_images(image_paths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa74528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "def plot_class_distribution(labels):\n",
    "    \"\"\"Visualize class distribution.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    classes = ['Benign', 'Malignant']\n",
    "    counts = [labels.count(0), labels.count(1)]\n",
    "    colors = ['#4CAF50', '#f44336']\n",
    "    \n",
    "    bars = ax.bar(classes, counts, color=colors, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20,\n",
    "                f'{count}', ha='center', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel('Number of Images', fontsize=12)\n",
    "    ax.set_title('Class Distribution in Dataset', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylim(0, max(counts) * 1.15)\n",
    "    \n",
    "    # Add percentage\n",
    "    total = sum(counts)\n",
    "    for i, (bar, count) in enumerate(zip(bars, counts)):\n",
    "        pct = count / total * 100\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height()/2,\n",
    "                f'{pct:.1f}%', ha='center', va='center', fontsize=12, color='white', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Statistics:\")\n",
    "    print(f\"   Total: {total} images\")\n",
    "    print(f\"   Benign: {counts[0]} ({counts[0]/total*100:.1f}%)\")\n",
    "    print(f\"   Malignant: {counts[1]} ({counts[1]/total*100:.1f}%)\")\n",
    "\n",
    "if len(labels) > 0:\n",
    "    plot_class_distribution(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bbe99",
   "metadata": {},
   "source": [
    "## 4. Data Preparation (Train/Val/Test Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf901cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CRITICAL: Proper data split to avoid data leakage\n",
    "# ============================================================\n",
    "\n",
    "# First split: separate test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    image_paths, labels,\n",
    "    test_size=CONFIG['test_split'],\n",
    "    random_state=CONFIG['seed'],\n",
    "    stratify=labels  # Maintain class balance\n",
    ")\n",
    "\n",
    "# Second split: separate validation from training\n",
    "val_ratio = CONFIG['val_split'] / (1 - CONFIG['test_split'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval,\n",
    "    test_size=val_ratio,\n",
    "    random_state=CONFIG['seed'],\n",
    "    stratify=y_trainval\n",
    ")\n",
    "\n",
    "print(\"üìä Data Split (Stratified):\")\n",
    "print(f\"   Training:   {len(X_train)} images ({len(X_train)/len(image_paths)*100:.1f}%)\")\n",
    "print(f\"   Validation: {len(X_val)} images ({len(X_val)/len(image_paths)*100:.1f}%)\")\n",
    "print(f\"   Test:       {len(X_test)} images ({len(X_test)/len(image_paths)*100:.1f}%)\")\n",
    "print()\n",
    "print(\"   Class balance in splits:\")\n",
    "print(f\"   Train - Benign: {y_train.count(0)}, Malignant: {y_train.count(1)}\")\n",
    "print(f\"   Val   - Benign: {y_val.count(0)}, Malignant: {y_val.count(1)}\")\n",
    "print(f\"   Test  - Benign: {y_test.count(0)}, Malignant: {y_test.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36095aa0",
   "metadata": {},
   "source": [
    "## 5. Dataset & DataLoaders with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d838202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Custom Dataset Class\n",
    "# ============================================================\n",
    "\n",
    "class BreastCancerDataset(Dataset):\n",
    "    \"\"\"Custom dataset for breast cancer histopathology images.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get label\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Data Augmentation Transforms\n",
    "# ============================================================\n",
    "\n",
    "# ImageNet normalization (required for pretrained ResNet)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Training transforms (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Transforms defined\")\n",
    "print(\"   Training: Resize ‚Üí Flip ‚Üí Rotate ‚Üí ColorJitter ‚Üí Normalize\")\n",
    "print(\"   Val/Test: Resize ‚Üí Normalize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a729ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = BreastCancerDataset(X_train, y_train, transform=train_transform)\n",
    "val_dataset = BreastCancerDataset(X_val, y_val, transform=val_transform)\n",
    "test_dataset = BreastCancerDataset(X_test, y_test, transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DataLoaders created\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebdbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmentations\n",
    "def show_augmentations(original_path):\n",
    "    \"\"\"Show original image and augmented versions.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    \n",
    "    # Load original\n",
    "    original = Image.open(original_path).convert('RGB')\n",
    "    \n",
    "    # Show original\n",
    "    axes[0, 0].imshow(original)\n",
    "    axes[0, 0].set_title('Original', fontsize=10)\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Show augmented versions\n",
    "    for i in range(1, 10):\n",
    "        row = i // 5\n",
    "        col = i % 5\n",
    "        \n",
    "        # Apply augmentation\n",
    "        aug_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        ])\n",
    "        \n",
    "        augmented = aug_transform(original)\n",
    "        axes[row, col].imshow(augmented)\n",
    "        axes[row, col].set_title(f'Augmented {i}', fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.suptitle('Data Augmentation Examples', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show augmentation on a sample image\n",
    "if len(X_train) > 0:\n",
    "    show_augmentations(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04d502",
   "metadata": {},
   "source": [
    "## 6. Model Architecture (ResNet50 Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf29ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ResNet50 with Custom Classifier\n",
    "# ============================================================\n",
    "\n",
    "def create_model(pretrained=True, num_classes=2):\n",
    "    \"\"\"ResNet50 with custom classifier for binary classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, pretrained=True, num_classes=2):\n",
    "        super(BreastCancerResNet, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        self.resnet = models.resnet50(weights='IMAGENET1K_V2' if pretrained else None)\n",
    "        \n",
    "        # Freeze early layers (optional - can unfreeze for fine-tuning)\n",
    "        for param in list(self.resnet.parameters())[:-20]:  # Freeze all but last few layers\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "    \n",
    "    def unfreeze_all(self):\n",
    "        \"\"\"Unfreeze all layers for full fine-tuning.\"\"\"\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# Create model\n",
    "model = BreastCancerResNet(pretrained=True, num_classes=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"‚úÖ Model created and moved to {device}\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   Frozen parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c8b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "\n",
    "# Class weights for imbalanced data\n",
    "class_counts = [y_train.count(0), y_train.count(1)]\n",
    "class_weights = torch.tensor([1.0 / c for c in class_counts], dtype=torch.float32)\n",
    "class_weights = class_weights / class_weights.sum()  # Normalize\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "print(f\"Class weights: Benign={class_weights[0]:.3f}, Malignant={class_weights[1]:.3f}\")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer (only trainable parameters)\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Optimizer and scheduler configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86f9cd",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Training Functions\n",
    "# ============================================================\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training', leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validating', leave=False):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store for AUC\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]  # Probability of malignant\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    epoch_auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING\n",
    "# ============================================================\n",
    "\n",
    "print(\"üöÄ Starting Training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_auc': []\n",
    "}\n",
    "\n",
    "best_val_auc = 0.0\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_auc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_auc'].append(val_auc)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save model\n",
    "        os.makedirs(os.path.dirname(CONFIG['model_save_path']), exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_auc': val_auc,\n",
    "            'val_acc': val_acc,\n",
    "            'config': CONFIG\n",
    "        }, CONFIG['model_save_path'])\n",
    "        print(f\"   ‚úÖ Best model saved! (AUC: {val_auc:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"   ‚è≥ No improvement ({patience_counter}/{CONFIG['patience']})\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= CONFIG['patience']:\n",
    "        print(f\"\\n‚ö†Ô∏è Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Training Complete!\")\n",
    "print(f\"   Best Val Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"   Best Val AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Visualize training progress.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train', linewidth=2)\n",
    "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Validation', linewidth=2)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss over Epochs')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(epochs, history['train_acc'], 'b-', label='Train', linewidth=2)\n",
    "    axes[1].plot(epochs, history['val_acc'], 'r-', label='Validation', linewidth=2)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy over Epochs')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # AUC\n",
    "    axes[2].plot(epochs, history['val_auc'], 'g-', label='Val AUC', linewidth=2)\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('AUC-ROC')\n",
    "    axes[2].set_title('Validation AUC over Epochs')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620033ce",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f373ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "checkpoint = torch.load(CONFIG['model_save_path'], map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"‚úÖ Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"   Validation AUC: {checkpoint['val_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01739fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPREHENSIVE TEST SET EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_model(model, loader, device):\n",
    "    \"\"\"Comprehensive model evaluation.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Evaluating'):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # Prob of malignant\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_probs), np.array(all_labels)\n",
    "\n",
    "test_preds, test_probs, test_labels = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f47875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# METRICS\n",
    "# ============================================================\n",
    "\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "test_auc = roc_auc_score(test_labels, test_probs)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä TEST SET RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüéØ Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"üìà AUC-ROC:  {test_auc:.4f}\")\n",
    "print()\n",
    "\n",
    "# Classification Report\n",
    "print(\"üìã Classification Report:\")\n",
    "print(\"-\"*40)\n",
    "print(classification_report(test_labels, test_preds, target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c674f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Benign', 'Malignant'],\n",
    "                yticklabels=['Benign', 'Malignant'],\n",
    "                annot_kws={'size': 16})\n",
    "    \n",
    "    ax.set_xlabel('Predicted', fontsize=12)\n",
    "    ax.set_ylabel('Actual', fontsize=12)\n",
    "    ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add percentages\n",
    "    total = cm.sum()\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            pct = cm[i, j] / total * 100\n",
    "            ax.text(j + 0.5, i + 0.7, f'({pct:.1f}%)', \n",
    "                   ha='center', va='center', fontsize=10, color='gray')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print metrics from confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    print(f\"\\nüìä Detailed Metrics:\")\n",
    "    print(f\"   True Negatives (Benign correct):  {tn}\")\n",
    "    print(f\"   True Positives (Malignant correct): {tp}\")\n",
    "    print(f\"   False Negatives (Missed cancers): {fn}\")\n",
    "    print(f\"   False Positives (False alarms):   {fp}\")\n",
    "    print(f\"\\n   Sensitivity (Recall): {sensitivity:.4f} - Ability to detect cancer\")\n",
    "    print(f\"   Specificity: {specificity:.4f} - Ability to rule out cancer\")\n",
    "    print(f\"   Precision: {precision:.4f} - Positive predictive value\")\n",
    "\n",
    "plot_confusion_matrix(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve and Precision-Recall Curve\n",
    "def plot_curves(y_true, y_probs):\n",
    "    \"\"\"Plot ROC and Precision-Recall curves.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    \n",
    "    axes[0].plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC Curve (AUC = {auc:.4f})')\n",
    "    axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "    axes[0].fill_between(fpr, tpr, alpha=0.3)\n",
    "    axes[0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "    axes[0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "    axes[0].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(loc='lower right')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    axes[0].scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=100, \n",
    "                   label=f'Optimal (threshold={optimal_threshold:.3f})')\n",
    "    axes[0].legend(loc='lower right')\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
    "    \n",
    "    axes[1].plot(recall, precision, 'g-', linewidth=2, label='PR Curve')\n",
    "    axes[1].fill_between(recall, precision, alpha=0.3, color='green')\n",
    "    axes[1].set_xlabel('Recall', fontsize=12)\n",
    "    axes[1].set_ylabel('Precision', fontsize=12)\n",
    "    axes[1].set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(loc='lower left')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìå Optimal Classification Threshold: {optimal_threshold:.4f}\")\n",
    "\n",
    "plot_curves(test_labels, test_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d45902",
   "metadata": {},
   "source": [
    "## 9. GradCAM Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GradCAM Implementation\n",
    "# ============================================================\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"GradCAM for ResNet50.\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Hook the last conv layer (layer4)\n",
    "        target_layer = model.resnet.layer4[-1]\n",
    "        target_layer.register_forward_hook(self._forward_hook)\n",
    "        target_layer.register_full_backward_hook(self._backward_hook)\n",
    "    \n",
    "    def _forward_hook(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def _backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def generate(self, image, target_class=None):\n",
    "        \"\"\"Generate GradCAM heatmap.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = self.model(image)\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = output.argmax(dim=1).item()\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0, target_class] = 1\n",
    "        output.backward(gradient=one_hot)\n",
    "        \n",
    "        # Compute GradCAM\n",
    "        pooled_gradients = self.gradients.mean(dim=[2, 3], keepdim=True)\n",
    "        cam = (self.activations * pooled_gradients).sum(dim=1, keepdim=True)\n",
    "        cam = F.relu(cam)\n",
    "        cam = F.interpolate(cam, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Normalize\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        \n",
    "        return cam\n",
    "\n",
    "# Create GradCAM\n",
    "gradcam = GradCAM(model)\n",
    "print(\"‚úÖ GradCAM initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GradCAM on sample images\n",
    "def visualize_gradcam(model, gradcam, image_paths, labels, n_samples=4):\n",
    "    \"\"\"Visualize GradCAM attention maps.\"\"\"\n",
    "    \n",
    "    # Get samples from each class\n",
    "    benign_idx = [i for i, l in enumerate(labels) if l == 0][:n_samples//2]\n",
    "    malig_idx = [i for i, l in enumerate(labels) if l == 1][:n_samples//2]\n",
    "    indices = benign_idx + malig_idx\n",
    "    \n",
    "    fig, axes = plt.subplots(len(indices), 3, figsize=(12, 4*len(indices)))\n",
    "    \n",
    "    for row, idx in enumerate(indices):\n",
    "        # Load image\n",
    "        img_path = image_paths[idx]\n",
    "        true_label = labels[idx]\n",
    "        \n",
    "        original_img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Transform for model\n",
    "        img_tensor = val_transform(original_img).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            pred_class = output.argmax(dim=1).item()\n",
    "            confidence = probs[0, pred_class].item()\n",
    "        \n",
    "        # Generate GradCAM\n",
    "        cam = gradcam.generate(img_tensor, target_class=pred_class)\n",
    "        \n",
    "        # Original image\n",
    "        axes[row, 0].imshow(original_img)\n",
    "        true_str = 'Benign' if true_label == 0 else 'Malignant'\n",
    "        axes[row, 0].set_title(f'Original\\nTrue: {true_str}', fontsize=10)\n",
    "        axes[row, 0].axis('off')\n",
    "        \n",
    "        # GradCAM heatmap\n",
    "        axes[row, 1].imshow(cam, cmap='jet')\n",
    "        pred_str = 'Benign' if pred_class == 0 else 'Malignant'\n",
    "        color = 'green' if pred_class == true_label else 'red'\n",
    "        axes[row, 1].set_title(f'GradCAM\\nPred: {pred_str} ({confidence:.1%})', \n",
    "                              fontsize=10, color=color)\n",
    "        axes[row, 1].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        img_resized = original_img.resize((224, 224))\n",
    "        overlay = np.array(img_resized) / 255.0\n",
    "        heatmap = plt.cm.jet(cam)[:, :, :3]\n",
    "        combined = overlay * 0.6 + heatmap * 0.4\n",
    "        \n",
    "        axes[row, 2].imshow(combined)\n",
    "        axes[row, 2].set_title('Overlay', fontsize=10)\n",
    "        axes[row, 2].axis('off')\n",
    "    \n",
    "    plt.suptitle('GradCAM Attention Visualization', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize on test images\n",
    "visualize_gradcam(model, gradcam, X_test, y_test, n_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b77dc",
   "metadata": {},
   "source": [
    "## 10. Export Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b256f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL MODEL EXPORT\n",
    "# ============================================================\n",
    "\n",
    "# Save complete model info\n",
    "final_model_path = CONFIG['model_save_path'].replace('.pth', '_final.pth')\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'metrics': {\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_auc': test_auc,\n",
    "    },\n",
    "    'class_names': ['Benign', 'Malignant'],\n",
    "    'input_size': CONFIG['image_size'],\n",
    "    'normalization': {\n",
    "        'mean': IMAGENET_MEAN,\n",
    "        'std': IMAGENET_STD\n",
    "    }\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {final_model_path}\")\n",
    "print(f\"\\nüìä Final Test Metrics:\")\n",
    "print(f\"   Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"   AUC-ROC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2548619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# INFERENCE FUNCTION (for use in app)\n",
    "# ============================================================\n",
    "\n",
    "def predict_single_image(model, image_path_or_pil, device):\n",
    "    \"\"\"\n",
    "    Predict on a single image.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        image_path_or_pil: Path to image or PIL Image\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        prediction: 'Benign' or 'Malignant'\n",
    "        confidence: Probability of predicted class\n",
    "        probabilities: [prob_benign, prob_malignant]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load image\n",
    "    if isinstance(image_path_or_pil, str):\n",
    "        image = Image.open(image_path_or_pil).convert('RGB')\n",
    "    else:\n",
    "        image = image_path_or_pil.convert('RGB')\n",
    "    \n",
    "    # Transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    ])\n",
    "    \n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        pred_class = output.argmax(dim=1).item()\n",
    "    \n",
    "    class_names = ['Benign', 'Malignant']\n",
    "    prediction = class_names[pred_class]\n",
    "    confidence = probs[0, pred_class].item()\n",
    "    probabilities = probs[0].cpu().numpy()\n",
    "    \n",
    "    return prediction, confidence, probabilities\n",
    "\n",
    "# Test inference function\n",
    "if len(X_test) > 0:\n",
    "    test_img = X_test[0]\n",
    "    pred, conf, probs = predict_single_image(model, test_img, device)\n",
    "    print(f\"\\nüß™ Test Inference:\")\n",
    "    print(f\"   Image: {test_img}\")\n",
    "    print(f\"   Prediction: {pred}\")\n",
    "    print(f\"   Confidence: {conf:.4f}\")\n",
    "    print(f\"   Benign prob: {probs[0]:.4f}\")\n",
    "    print(f\"   Malignant prob: {probs[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c32b86",
   "metadata": {},
   "source": [
    "## 11. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìã TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"üî¨ MODEL ARCHITECTURE\")\n",
    "print(f\"   Base: ResNet50 (ImageNet pretrained)\")\n",
    "print(f\"   Custom classifier with dropout\")\n",
    "print(f\"   Total params: {total_params:,}\")\n",
    "print(f\"   Trainable params: {trainable_params:,}\")\n",
    "print()\n",
    "print(\"üìä DATASET\")\n",
    "print(f\"   Total images: {len(image_paths)}\")\n",
    "print(f\"   Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è TRAINING CONFIG\")\n",
    "print(f\"   Epochs: {len(history['train_loss'])}\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"   Augmentation: Flip, Rotate, ColorJitter\")\n",
    "print()\n",
    "print(\"üéØ FINAL RESULTS (Test Set)\")\n",
    "print(f\"   Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"   AUC-ROC: {test_auc:.4f}\")\n",
    "print()\n",
    "print(\"üíæ SAVED FILES\")\n",
    "print(f\"   Model: {final_model_path}\")\n",
    "print()\n",
    "print(\"‚úÖ Ready for deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3092f0e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Next Steps\n",
    "\n",
    "1. **Copy the trained model** (`models/imaging_model_trained_final.pth`) to your breast_cancer_ai project\n",
    "\n",
    "2. **Update `modules/imaging.py`** to load the trained model instead of generic pretrained ResNet50\n",
    "\n",
    "3. **Important Notes:**\n",
    "   - If accuracy is low, try:\n",
    "     - More epochs\n",
    "     - Unfreezing more layers (`model.unfreeze_all()`)\n",
    "     - More data augmentation\n",
    "     - Lower learning rate\n",
    "   - For production, consider:\n",
    "     - Cross-validation\n",
    "     - Test-time augmentation (TTA)\n",
    "     - Model ensembling"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
