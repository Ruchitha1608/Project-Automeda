"""
ğŸ“Š Generate Comprehensive Imaging Model Report
This script evaluates the trained model and generates full documentation
"""

import os
import numpy as np
from PIL import Image
from pathlib import Path
from collections import Counter
import json
from datetime import datetime

# PyTorch
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import torch.nn.functional as F

# Sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, roc_auc_score, confusion_matrix, 
    classification_report, precision_score, recall_score, f1_score
)

# ============================================================
# CONFIGURATION
# ============================================================

CONFIG = {
    'data_dir': 'data/Breakhis-400x',
    'model_path': 'models/imaging_model_trained.pth',
    'batch_size': 32,
    'image_size': 224,
    'val_split': 0.15,
    'test_split': 0.15,
    'seed': 42
}

# Set seeds
torch.manual_seed(CONFIG['seed'])
np.random.seed(CONFIG['seed'])

# Device
device = torch.device('cuda' if torch.cuda.is_available() else 
                      'mps' if torch.backends.mps.is_available() else 'cpu')

# ============================================================
# DATA LOADING
# ============================================================

def load_data(data_dir):
    """Load image paths and labels."""
    data_dir = Path(data_dir)
    
    image_paths = []
    labels = []
    
    # Benign (label=0)
    benign_dir = data_dir / 'benign'
    for ext in ['*.png', '*.jpg', '*.jpeg']:
        for img_path in benign_dir.glob(ext):
            image_paths.append(str(img_path))
            labels.append(0)
    
    # Malignant (label=1)
    malignant_dir = data_dir / 'malignant'
    for ext in ['*.png', '*.jpg', '*.jpeg']:
        for img_path in malignant_dir.glob(ext):
            image_paths.append(str(img_path))
            labels.append(1)
    
    return image_paths, labels

# ============================================================
# DATASET
# ============================================================

IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

class BreastCancerDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, self.labels[idx]

val_transform = transforms.Compose([
    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),
    transforms.ToTensor(),
    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)
])

# ============================================================
# MODEL
# ============================================================

def create_model():
    """Create model architecture matching training."""
    model = models.resnet50(weights=None)
    num_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(num_features, 512),
        nn.ReLU(),
        nn.BatchNorm1d(512),
        nn.Dropout(0.3),
        nn.Linear(512, 2)
    )
    return model

# ============================================================
# EVALUATION
# ============================================================

def evaluate_model(model, loader, device):
    """Comprehensive model evaluation."""
    model.eval()
    
    all_preds = []
    all_probs = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in loader:
            images = images.to(device)
            
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)
            _, preds = torch.max(outputs, 1)
            
            all_preds.extend(preds.cpu().numpy())
            all_probs.extend(probs[:, 1].cpu().numpy())
            all_labels.extend(labels.numpy())
    
    return np.array(all_preds), np.array(all_probs), np.array(all_labels)

# ============================================================
# MAIN REPORT GENERATION
# ============================================================

def generate_report():
    print("="*70)
    print("ğŸ”¬ BREAST CANCER HISTOPATHOLOGY CLASSIFICATION - FULL REPORT")
    print("="*70)
    print(f"\nğŸ“… Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ–¥ï¸  Device: {device}")
    
    # Load checkpoint
    checkpoint = torch.load(CONFIG['model_path'], map_location=device, weights_only=False)
    saved_config = checkpoint.get('config', CONFIG)
    
    print("\n" + "="*70)
    print("ğŸ“‹ SECTION 1: TRAINING CONFIGURATION")
    print("="*70)
    print(f"""
    Parameter               Value
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Model Architecture      ResNet50 (Transfer Learning)
    Pretrained Weights      ImageNet V2
    Input Image Size        {saved_config.get('image_size', 224)} x {saved_config.get('image_size', 224)} pixels
    Batch Size              {saved_config.get('batch_size', 32)}
    Learning Rate           {saved_config.get('learning_rate', 0.0001)}
    Max Epochs              {saved_config.get('num_epochs', 20)}
    Early Stopping          Patience = {saved_config.get('patience', 5)}
    Optimizer               AdamW
    Loss Function           CrossEntropyLoss (weighted)
    Random Seed             {saved_config.get('seed', 42)}
    """)
    
    # Load data
    print("\n" + "="*70)
    print("ğŸ“Š SECTION 2: DATASET INFORMATION")
    print("="*70)
    
    image_paths, labels = load_data(CONFIG['data_dir'])
    total_images = len(image_paths)
    benign_count = labels.count(0)
    malignant_count = labels.count(1)
    
    print(f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    BREAKHIS DATASET (400x)                      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Total Images:              {total_images:>6}                              â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
    â”‚  Benign Images:             {benign_count:>6}  ({benign_count/total_images*100:>5.1f}%)                    â”‚
    â”‚  Malignant Images:          {malignant_count:>6}  ({malignant_count/total_images*100:>5.1f}%)                    â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
    â”‚  Class Imbalance Ratio:     1:{malignant_count/benign_count:.2f} (Benign:Malignant)            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    # Data split
    X_trainval, X_test, y_trainval, y_test = train_test_split(
        image_paths, labels, test_size=CONFIG['test_split'],
        random_state=CONFIG['seed'], stratify=labels
    )
    
    val_ratio = CONFIG['val_split'] / (1 - CONFIG['test_split'])
    X_train, X_val, y_train, y_val = train_test_split(
        X_trainval, y_trainval, test_size=val_ratio,
        random_state=CONFIG['seed'], stratify=y_trainval
    )
    
    print("\n" + "="*70)
    print("ğŸ“‚ SECTION 3: DATA SPLIT (STRATIFIED)")
    print("="*70)
    print(f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         DATA PARTITIONING                             â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Split           Images    Percentage    Benign    Malignant         â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
    â”‚  Training        {len(X_train):>6}      {len(X_train)/total_images*100:>5.1f}%       {y_train.count(0):>5}      {y_train.count(1):>5}            â”‚
    â”‚  Validation      {len(X_val):>6}      {len(X_val)/total_images*100:>5.1f}%       {y_val.count(0):>5}      {y_val.count(1):>5}            â”‚
    â”‚  Test            {len(X_test):>6}      {len(X_test)/total_images*100:>5.1f}%       {y_test.count(0):>5}      {y_test.count(1):>5}            â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
    â”‚  TOTAL           {total_images:>6}      100.0%       {benign_count:>5}      {malignant_count:>5}            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Split Ratios:
    â€¢ Training:   70% (for model learning)
    â€¢ Validation: 15% (for hyperparameter tuning & early stopping)
    â€¢ Test:       15% (for final unbiased evaluation)
    
    Note: Stratified split ensures class proportions are maintained in all sets.
    """)
    
    # Load model
    print("\n" + "="*70)
    print("ğŸ§  SECTION 4: MODEL ARCHITECTURE")
    print("="*70)
    
    model = create_model()
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   ResNet50 ARCHITECTURE                         â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Base Model:           ResNet50 (50 layers deep)                â”‚
    â”‚  Pretrained On:        ImageNet (1.2M images, 1000 classes)     â”‚
    â”‚  Transfer Learning:    Feature extraction + Fine-tuning         â”‚
    â”‚                                                                 â”‚
    â”‚  CUSTOM CLASSIFIER HEAD:                                        â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  Layer 1: Dropout(0.5)                                          â”‚
    â”‚  Layer 2: Linear(2048 â†’ 512) + ReLU                             â”‚
    â”‚  Layer 3: BatchNorm1d(512)                                      â”‚
    â”‚  Layer 4: Dropout(0.3)                                          â”‚
    â”‚  Layer 5: Linear(512 â†’ 2)  [Output: Benign/Malignant]           â”‚
    â”‚                                                                 â”‚
    â”‚  PARAMETERS:                                                    â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  Total Parameters:     {total_params:>12,}                          â”‚
    â”‚  Trainable Parameters: {trainable_params:>12,}                          â”‚
    â”‚  Frozen Parameters:    {total_params - trainable_params:>12,}                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    print("\n" + "="*70)
    print("ğŸ“ˆ SECTION 5: TRAINING PROCESS")
    print("="*70)
    print(f"""
    TRAINING METHODOLOGY:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    1. DATA AUGMENTATION (Training Set Only):
       â€¢ Random Horizontal Flip (p=0.5)
       â€¢ Random Vertical Flip (p=0.5)
       â€¢ Random Rotation (Â±15Â°)
       â€¢ Color Jitter (brightness=0.2, contrast=0.2)
       â€¢ ImageNet Normalization (mean=[0.485, 0.456, 0.406], 
                                  std=[0.229, 0.224, 0.225])
    
    2. OPTIMIZATION:
       â€¢ Optimizer: AdamW with weight decay
       â€¢ Learning Rate: {saved_config.get('learning_rate', 0.0001)}
       â€¢ LR Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)
       â€¢ Class Weights: Applied to handle imbalanced data
    
    3. EARLY STOPPING:
       â€¢ Monitor: Validation AUC-ROC
       â€¢ Patience: {saved_config.get('patience', 5)} epochs
       â€¢ Best model saved when validation AUC improves
    
    4. TRAINING RESULTS:
       â€¢ Best Validation Accuracy: {checkpoint.get('val_acc', 0)*100:.2f}%
       â€¢ Best Validation AUC-ROC:  {checkpoint.get('val_auc', 0):.4f}
    """)
    
    # Test evaluation
    print("\n" + "="*70)
    print("ğŸ¯ SECTION 6: TEST SET EVALUATION")
    print("="*70)
    
    test_dataset = BreastCancerDataset(X_test, y_test, val_transform)
    test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)
    
    test_preds, test_probs, test_labels = evaluate_model(model, test_loader, device)
    
    # Calculate metrics
    test_acc = accuracy_score(test_labels, test_preds)
    test_auc = roc_auc_score(test_labels, test_probs)
    precision = precision_score(test_labels, test_preds)
    recall = recall_score(test_labels, test_preds)
    f1 = f1_score(test_labels, test_preds)
    
    print(f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    PERFORMANCE METRICS                          â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                                 â”‚
    â”‚  OVERALL METRICS:                                               â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  Accuracy:             {test_acc*100:>6.2f}%                                â”‚
    â”‚  AUC-ROC:              {test_auc:>6.4f}                                 â”‚
    â”‚  F1-Score:             {f1:>6.4f}                                 â”‚
    â”‚                                                                 â”‚
    â”‚  CLASS-SPECIFIC METRICS (Malignant = Positive):                 â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  Precision:            {precision*100:>6.2f}%  (PPV)                       â”‚
    â”‚  Recall/Sensitivity:   {recall*100:>6.2f}%  (True Positive Rate)          â”‚
    â”‚  Specificity:          {(test_labels[test_preds == 0] == 0).sum() / (test_labels == 0).sum() * 100:>6.2f}%  (True Negative Rate)          â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    # Confusion Matrix
    cm = confusion_matrix(test_labels, test_preds)
    tn, fp, fn, tp = cm.ravel()
    
    print(f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    CONFUSION MATRIX                             â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                                 â”‚
    â”‚                         PREDICTED                               â”‚
    â”‚                    Benign      Malignant                        â”‚
    â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
    â”‚      Benign   â”‚    {tn:>4}    â”‚    {fp:>4}    â”‚  â† Actual Benign      â”‚
    â”‚   A  â”€â”€â”€â”€â”€â”€â”€â”€  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
    â”‚   C  Malignant â”‚    {fn:>4}    â”‚    {tp:>4}    â”‚  â† Actual Malignant   â”‚
    â”‚   T           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
    â”‚   U               â†‘            â†‘                                â”‚
    â”‚   A           Pred Benign  Pred Malignant                       â”‚
    â”‚   L                                                             â”‚
    â”‚                                                                 â”‚
    â”‚  INTERPRETATION:                                                â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  True Negatives (TN):  {tn:>4}  Benign correctly identified        â”‚
    â”‚  True Positives (TP):  {tp:>4}  Malignant correctly identified     â”‚
    â”‚  False Positives (FP): {fp:>4}  Benign misclassified as Malignant  â”‚
    â”‚  False Negatives (FN): {fn:>4}  Malignant misclassified as Benign  â”‚
    â”‚                                                                 â”‚
    â”‚  âš ï¸  False Negatives are CRITICAL in cancer detection!          â”‚
    â”‚      These represent missed cancer cases.                       â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    # Classification report
    print("\n" + "="*70)
    print("ğŸ“‹ SECTION 7: DETAILED CLASSIFICATION REPORT")
    print("="*70)
    print()
    print(classification_report(test_labels, test_preds, 
                                target_names=['Benign', 'Malignant'],
                                digits=4))
    
    # Summary
    print("\n" + "="*70)
    print("ğŸ“ SECTION 8: EXECUTIVE SUMMARY")
    print("="*70)
    print(f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘              MODEL PERFORMANCE SUMMARY                          â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                                                 â•‘
    â•‘  Dataset: BreakHis 400x Magnification                           â•‘
    â•‘  Total Images: {total_images}                                          â•‘
    â•‘  Test Set Size: {len(X_test)} images                                     â•‘
    â•‘                                                                 â•‘
    â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
    â•‘  â”‚  KEY RESULTS:                                           â”‚    â•‘
    â•‘  â”‚  â€¢ Accuracy:    {test_acc*100:.2f}%                                â”‚    â•‘
    â•‘  â”‚  â€¢ AUC-ROC:     {test_auc:.4f}                               â”‚    â•‘
    â•‘  â”‚  â€¢ Sensitivity: {recall*100:.2f}% (Cancer detection rate)       â”‚    â•‘
    â•‘  â”‚  â€¢ Specificity: {(tn/(tn+fp))*100:.2f}% (Correct benign ID)          â”‚    â•‘
    â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
    â•‘                                                                 â•‘
    â•‘  CLINICAL INTERPRETATION:                                       â•‘
    â•‘  â€¢ Model correctly identifies {recall*100:.1f}% of cancer cases         â•‘
    â•‘  â€¢ {fn} malignant cases were missed (False Negatives)              â•‘
    â•‘  â€¢ {fp} benign cases were flagged as malignant (False Positives)   â•‘
    â•‘                                                                 â•‘
    â•‘  RECOMMENDATION: âœ… Model suitable for clinical decision supportâ•‘
    â•‘  Note: Should be used alongside expert pathologist review       â•‘
    â•‘                                                                 â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("\n" + "="*70)
    print("ğŸ“ SECTION 9: FILES & ARTIFACTS")
    print("="*70)
    print(f"""
    Generated Files:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â€¢ Trained Model:     models/imaging_model_trained.pth ({os.path.getsize('models/imaging_model_trained.pth')/1024/1024:.1f} MB)
    â€¢ Training Script:   train_imaging_model.py
    â€¢ Colab Notebook:    notebooks/Imaging_Model_Training.ipynb
    â€¢ This Report:       Run generate_imaging_report.py
    
    Model Checkpoint Contains:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â€¢ model_state_dict: Trained weights
    â€¢ val_auc: Best validation AUC score
    â€¢ val_acc: Best validation accuracy
    â€¢ config: Training configuration
    """)
    
    print("\n" + "="*70)
    print("âœ… REPORT COMPLETE")
    print("="*70)
    
    # Return metrics for further use
    return {
        'total_images': total_images,
        'benign_count': benign_count,
        'malignant_count': malignant_count,
        'train_size': len(X_train),
        'val_size': len(X_val),
        'test_size': len(X_test),
        'test_accuracy': test_acc,
        'test_auc': test_auc,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'confusion_matrix': cm.tolist()
    }

if __name__ == '__main__':
    metrics = generate_report()
